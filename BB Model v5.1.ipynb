{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.backend import clear_session\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clean_bb_10k_comments.json') as json_file:  #first 1mill bb comments\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bb_tok = Tokenizer(oov_token='<unk>')\n",
    "bb_tok.fit_on_texts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bb_tok.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baby-steps.ipynb              hp-v5.2-tok.pickle\r\n",
      "bb-1m-tok.pickle              hp-v5-tok.pickle\r\n",
      "bb-500k-tok.pickle            huffpo-data-cleaning.ipynb\r\n",
      "bb-50k-tok-base.pickle        huffpo-model-v0.ipynb\r\n",
      "bb-50k-tok.pickle             Huffpo Model v1.0.ipynb\r\n",
      "bb_all_comments.csv           Huffpo Model v1.0.py\r\n",
      "BB Model v1.0.ipynb           huffpo-model-v1.ipynb\r\n",
      "BB Model v2.ipynb             huffpo-model-v1.py\r\n",
      "BB Model v3.ipynb             Huffpo Model v4.ipynb\r\n",
      "BB Model v4.ipynb             Huffpo Model v5.1.ipynb\r\n",
      "BB Model v5.ipynb             Huffpo Model v5.2.ipynb\r\n",
      "bb-v1-tok.pickle              Huffpo Model v5-Copy1.ipynb\r\n",
      "bb-v2-tok.pickle              Huffpo Model v5.ipynb\r\n",
      "bb-v3.1-tok.pickle            huffpo-v1-tok.pickle\r\n",
      "bb-v5-tok.pickle              huffpo wordvectors v1.ipynb\r\n",
      "clean_bb_comments.json        investigation-Copy1.ipynb\r\n",
      "clean_hp_1k_comments.json     investigation.ipynb\r\n",
      "clean_hp_comments.json        \u001b[0m\u001b[1;35mmodels\u001b[0m/\r\n",
      "combined-comment-tokens.json  \u001b[1;35mold\u001b[0m/\r\n",
      "comments_csv                  play.ipynb\r\n",
      "Demo.ipynb                    preprocess-old.ipynb\r\n",
      "Demo-old.ipynb                preprocess-text.ipynb\r\n",
      "hp-1m-tok.pickle              \u001b[1;35m__pycache__\u001b[0m/\r\n",
      "hp-2m-tok.pickle              \u001b[1;35mraw-data\u001b[0m/\r\n",
      "hp-500k-tok.pickle            Spots EDA.ipynb\r\n",
      "hp-50k-tok-base.pickle        \u001b[1;35mtensorboard-logs\u001b[0m/\r\n",
      "hp-50k-tok.pickle             test.json\r\n",
      "hp_all_comments.csv           \u001b[1;35mweights\u001b[0m/\r\n",
      "hp-v5.1-tok.pickle            \u001b[1;35mwordvecs\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bb-v5.1-tok.pickle', 'wb') as handle:\n",
    "    pickle.dump(bb_tok, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data = data\n",
    "\n",
    "seqs = bb_tok.texts_to_sequences(train_data)\n",
    "less_20_seqs = list(filter(lambda x: len(x) <20, seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "654993"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(less_20_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Seq Len: 19\n"
     ]
    }
   ],
   "source": [
    "MAXLEN = 19\n",
    "VOCAB = int(len(bb_tok.word_index))\n",
    "SEED = 42\n",
    "\n",
    "sequences = pad_sequences(less_20_seqs, maxlen=MAXLEN, padding='pre')\n",
    "\n",
    "print('Max Seq Len: %d' % MAXLEN)\n",
    "\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.15, random_state=SEED)\n",
    "\n",
    "\n",
    "#y_cat = to_categorical(y, num_classes=vocab_sz) #1-hot encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to optimize this later, use np arrays instead of python lists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, seqs took 57s to go through 1 mill samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 18, 300)           3000600   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 500)               1602000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10002)             5011002   \n",
      "=================================================================\n",
      "Total params: 9,613,602\n",
      "Trainable params: 9,613,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#NN definition\n",
    "model = Sequential()\n",
    "model.add(Embedding(VOCAB, 300, input_length=MAXLEN-1))\n",
    "model.add(LSTM(500))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(VOCAB, activation='softmax'))\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 551176 samples, validate on 5568 samples\n",
      "Epoch 1/200\n",
      "551176/551176 [==============================] - 240s 435us/step - loss: nan - acc: 0.1217 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.12172, saving model to weights/bb-v5.1/best-weights.hdf5\n",
      "Epoch 2/200\n",
      "551176/551176 [==============================] - 237s 430us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00002: acc did not improve from 0.12172\n",
      "Epoch 3/200\n",
      "551176/551176 [==============================] - 280s 508us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00003: acc did not improve from 0.12172\n",
      "Epoch 4/200\n",
      "551176/551176 [==============================] - 383s 695us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.12172\n",
      "Epoch 5/200\n",
      "551176/551176 [==============================] - 458s 830us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.12172\n",
      "Epoch 6/200\n",
      "551176/551176 [==============================] - 456s 828us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.12172\n",
      "Epoch 7/200\n",
      "551176/551176 [==============================] - 464s 841us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.12172\n",
      "Epoch 8/200\n",
      "551176/551176 [==============================] - 496s 899us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.12172\n",
      "Epoch 9/200\n",
      "551176/551176 [==============================] - 480s 871us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.12172\n",
      "Epoch 10/200\n",
      "551176/551176 [==============================] - 470s 852us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.12172\n",
      "Epoch 11/200\n",
      "551176/551176 [==============================] - 480s 871us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.12172\n",
      "Epoch 12/200\n",
      "551176/551176 [==============================] - 455s 825us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.12172\n",
      "Epoch 13/200\n",
      "551176/551176 [==============================] - 454s 824us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.12172\n",
      "Epoch 14/200\n",
      "551176/551176 [==============================] - 504s 914us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.12172\n",
      "Epoch 15/200\n",
      "551176/551176 [==============================] - 518s 940us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.12172\n",
      "Epoch 16/200\n",
      "551176/551176 [==============================] - 518s 940us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.12172\n",
      "Epoch 17/200\n",
      "551176/551176 [==============================] - 519s 942us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.12172\n",
      "Epoch 18/200\n",
      "551176/551176 [==============================] - 519s 941us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.12172\n",
      "Epoch 19/200\n",
      "551176/551176 [==============================] - 518s 940us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.12172\n",
      "Epoch 20/200\n",
      "551176/551176 [==============================] - 518s 940us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.12172\n",
      "Epoch 21/200\n",
      "551176/551176 [==============================] - 519s 942us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.12172\n",
      "Epoch 22/200\n",
      "551176/551176 [==============================] - 519s 942us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.12172\n",
      "Epoch 23/200\n",
      "551176/551176 [==============================] - 519s 941us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.12172\n",
      "Epoch 24/200\n",
      "551176/551176 [==============================] - 519s 941us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.12172\n",
      "Epoch 25/200\n",
      "551176/551176 [==============================] - 518s 940us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.12172\n",
      "Epoch 26/200\n",
      "551176/551176 [==============================] - 517s 938us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00026: acc did not improve from 0.12172\n",
      "Epoch 27/200\n",
      "551176/551176 [==============================] - 518s 939us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00027: acc did not improve from 0.12172\n",
      "Epoch 28/200\n",
      "551176/551176 [==============================] - 518s 940us/step - loss: nan - acc: 8.9082e-04 - val_loss: 9.2105 - val_acc: 5.3879e-04\n",
      "\n",
      "Epoch 00028: acc did not improve from 0.12172\n",
      "Epoch 29/200\n",
      "165600/551176 [========>.....................] - ETA: 6:02 - loss: 9.2105 - acc: 8.8768e-04"
     ]
    }
   ],
   "source": [
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"models/bb-model-v5.1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "fpath = \"weights/bb-v5.1/best-weights.hdf5\" #off of training acc\n",
    "checkpoint = ModelCheckpoint(fpath, monitor='acc', verbose=2, save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "BS = 100\n",
    "tb = TensorBoard(log_dir=\"tensorboard-logs/{}\".format('bb-modelv5.1'))\n",
    "callback_lst = [checkpoint, tb]\n",
    "#steps_per_epoch is num of batches that make up 1 epoch, defaults to size of train set\n",
    "model.fit(X_train,y_train,batch_size=BS, validation_split=.01, epochs=200, callbacks=callback_lst, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import emoji\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline-weights.hdf5  best-weights.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "%ls weights/huffpo-v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hp-v5-tok.pickle', 'rb') as handle:\n",
    "    hp_tok = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 18, 300)           3000600   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 500)               1602000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10002)             5011002   \n",
      "=================================================================\n",
      "Total params: 9,613,602\n",
      "Trainable params: 9,613,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "with open('models/hp-model-v5.json','r') as handle:\n",
    "    model_json = handle.read()\n",
    "    huffpo_model = model_from_json(model_json)\n",
    "huffpo_model.load_weights('weights/huffpo-v5/best-weights.hdf5')\n",
    "print(huffpo_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1;35mbb-v1\u001b[0m/    \u001b[1;35mbb-v4\u001b[0m/    \u001b[1;35mhuffpo-v1\u001b[0m/    \u001b[1;35mhuffpo-v5.2\u001b[0m/     \u001b[1;35mhuffpo-v6.1\u001b[0m/\r\n",
      "\u001b[1;35mbb-v2\u001b[0m/    \u001b[1;35mbb-v5\u001b[0m/    \u001b[1;35mhuffpo-v4\u001b[0m/    \u001b[1;35mhuffpo-v5.3\u001b[0m/     \u001b[1;35mhuffpo-v6.1-R2\u001b[0m/\r\n",
      "\u001b[1;35mbb-v3\u001b[0m/    \u001b[1;35mbb-v5.1\u001b[0m/  \u001b[1;35mhuffpo-v5\u001b[0m/    \u001b[1;35mhuffpo-v5.3-R2\u001b[0m/  \u001b[1;35mhuffpo-v6-R2\u001b[0m/\r\n",
      "\u001b[1;35mbb-v3.1\u001b[0m/  \u001b[1;35mbb-v5.2\u001b[0m/  \u001b[1;35mhuffpo-v5.1\u001b[0m/  \u001b[1;35mhuffpo-v6\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 18, 300)           3000600   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 500)               3204000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10002)             5011002   \n",
      "=================================================================\n",
      "Total params: 11,215,602\n",
      "Trainable params: 11,215,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "with open('hp-v5.2-tok.pickle', 'rb') as handle:\n",
    "    hp_bilstm_tok = pickle.load(handle)\n",
    "    \n",
    "with open('models/hp-model-v5.2.json','r') as handle:\n",
    "    model_json = handle.read()\n",
    "    huffpo_bilstm = model_from_json(model_json)\n",
    "huffpo_bilstm.load_weights('weights/huffpo-v5.2/best-weights.hdf5')\n",
    "print(huffpo_bilstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 6, 300)            3000600   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1000)              3204000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10002)             10012002  \n",
      "=================================================================\n",
      "Total params: 16,216,602\n",
      "Trainable params: 16,216,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "with open('hp-v5.2-tok.pickle', 'rb') as handle:\n",
    "    hp_bilstm_tok = pickle.load(handle)\n",
    "    \n",
    "with open('models/hp-model-v5.3.json','r') as handle:\n",
    "    model_json = handle.read()\n",
    "    huffpo_bilstm_v53 = model_from_json(model_json)\n",
    "huffpo_bilstm_v53.load_weights('weights/huffpo-v5.3-R2/best-weights.hdf5')\n",
    "print(huffpo_bilstm_v53.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "#seed_text is str\n",
    "MAX_LEN = 6\n",
    "\n",
    "\n",
    "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])\n",
    "        # pre-pad sequences to a fixed length\n",
    "        encoded = pad_sequences(encoded, maxlen=max_length, padding='pre')\n",
    "        pred_vector = model.predict(encoded, verbose=0)[0] #1 x 10002 vector of probabiltiies \n",
    "        class_preds = np.argsort(pred_vector)\n",
    "        class_preds = np.flip(class_preds) #1 x 10002 vector of word indexes, ordered from most-likely\n",
    "        top_pred = class_preds[0]\n",
    "        \n",
    "        if top_pred in tokenizer.index_word:\n",
    "            \n",
    "            nxt_word = tokenizer.index_word[top_pred]\n",
    "\n",
    "        else:\n",
    "            nxt_word = ' ??? '\n",
    "        \"\"\"\n",
    "        fix me. Almost there!\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    " \n",
    "\n",
    "\n",
    "        in_text += ' ' + nxt_word\n",
    "    return in_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trump 2020 oov same same thing bro ok oov oov oov lol ❤️ again oov oov'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_seq(huffpo_model, hp_tok, 18, \"trump\", 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trump 2016 oov oov oov oov oov oov oov oov oov oov oov oov oov oov'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_seq(huffpo_bilstm_v53, hp_bilstm_tok, 6, \"trump\", 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "INPUT_STR = 'trump is'\n",
    "test = hp_bilstm_tok.texts_to_sequences([INPUT_STR])\n",
    "encoded_input = pad_sequences(test, maxlen=MAX_LEN, padding='pre')\n",
    "pred_vector = huffpo_bilstm.predict(encoded_input, verbose=0)[0] #1 x 10002 vector of probabiltiies \n",
    "class_preds = np.argsort(pred_vector)\n",
    "class_preds = np.flip(class_preds) #1 x 10002 vector of word indexes, ordered from most-likely\n",
    "top_pred = class_preds[0]\n",
    "nxt_word = hp_bilstm_tok.index_word[top_pred]\n",
    "#print(len(pred_code))\n",
    "\n",
    "#pred_word = hp_bilstm_tok.sequences_to_texts(pred_code)\n",
    "#print(pred_word)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.backend import clear_session\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clean_bb_comments.json') as json_file:  #first 1mill bb comments\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bb_tok = Tokenizer(oov_token='<unk>')\n",
    "bb_tok.fit_on_texts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50002"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bb_tok.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bb-v5-tok.pickle', 'wb') as handle:\n",
    "    pickle.dump(bb_tok, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bb-500k-tok.pickle', 'rb') as handle:\n",
    "    bb_tok = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data = data\n",
    "\n",
    "seqs = bb_tok.texts_to_sequences(train_data)\n",
    "less_20_seqs = list(filter(lambda x: len(x) <20, seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "654993"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(less_20_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Seq Len: 19\n"
     ]
    }
   ],
   "source": [
    "MAXLEN = 19\n",
    "VOCAB = int(len(bb_tok.word_index))\n",
    "SEED = 42\n",
    "\n",
    "sequences = pad_sequences(less_20_seqs, maxlen=MAXLEN, padding='pre')\n",
    "\n",
    "print('Max Seq Len: %d' % MAXLEN)\n",
    "\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.15, random_state=SEED)\n",
    "\n",
    "\n",
    "#y_cat = to_categorical(y, num_classes=vocab_sz) #1-hot encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to optimize this later, use np arrays instead of python lists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, seqs took 57s to go through 1 mill samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 18, 300)           43245300  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 500)               1602000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 144151)            72219651  \n",
      "=================================================================\n",
      "Total params: 117,066,951\n",
      "Trainable params: 117,066,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#NN definition\n",
    "model = Sequential()\n",
    "model.add(Embedding(VOCAB, 300, input_length=MAXLEN-1))\n",
    "model.add(LSTM(500))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(VOCAB, activation='softmax'))\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 553960 samples, validate on 2784 samples\n",
      "Epoch 1/20\n",
      "553960/553960 [==============================] - 825s 1ms/step - loss: 8.6359 - acc: 0.0420 - val_loss: 8.5017 - val_acc: 0.0413\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.04131, saving model to weights/bb-v5/best-weights.hdf5\n",
      "Epoch 2/20\n",
      "101100/553960 [====>.........................] - ETA: 12:49 - loss: 8.4979 - acc: 0.0431"
     ]
    }
   ],
   "source": [
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"models/bb-model-v5.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "fpath = \"weights/bb-v5/best-weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(fpath, monitor='val_acc', verbose=2, save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "BS = 100\n",
    "tb = TensorBoard(log_dir=\"tensorboard-logs/{}\".format('bb-modelv5'))\n",
    "callback_lst = [checkpoint, tb]\n",
    "#steps_per_epoch is num of batches that make up 1 epoch, defaults to size of train set\n",
    "model.fit(X_train,y_train,batch_size=BS, validation_split=.005, epochs=20, callbacks=callback_lst, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

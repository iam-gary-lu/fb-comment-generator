{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing import text\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "#from keras.preprocessing.text import tokenizer_from_json\n",
    "import time as time\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>parent_comment_id</th>\n",
       "      <th>parent_post_id</th>\n",
       "      <th>num_angrys</th>\n",
       "      <th>num_hahas</th>\n",
       "      <th>num_loves</th>\n",
       "      <th>num_sads</th>\n",
       "      <th>num_thankfuls</th>\n",
       "      <th>num_wows</th>\n",
       "      <th>total_reaction</th>\n",
       "      <th>fb_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10159788572690354_10159788622410354</td>\n",
       "      <td>You'll have to survive the mass hysteria and c...</td>\n",
       "      <td>10159788572690354_10159788608450354</td>\n",
       "      <td>95475020353_10159788572690354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>brietbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10155327674521130_10155327912376130</td>\n",
       "      <td>Ummm...thanks. \"Not trying to be rude but\" is ...</td>\n",
       "      <td>10155327674521130_10155327709241130</td>\n",
       "      <td>18468761129_10155327674521130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>huffpo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1234985053182879_1235051949842856</td>\n",
       "      <td>Get rid of the cap all together. Include all w...</td>\n",
       "      <td>1234985053182879_1235001863181198</td>\n",
       "      <td>18468761129_10153685924816130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>huffpo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10156819866680354_1696714377242759</td>\n",
       "      <td>We will stay on the Trump train more than ever .</td>\n",
       "      <td>10156819866680354_10156819873650354</td>\n",
       "      <td>95475020353_10156819866680354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>brietbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10156242997995354_10156243051735354</td>\n",
       "      <td>Becca Portera But....but....Obamacare took car...</td>\n",
       "      <td>10156242997995354_10156243010900354</td>\n",
       "      <td>95475020353_10156242997995354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>brietbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>10157901701015354_10157901768510354</td>\n",
       "      <td>David\"  Hell the Democrats control the Media n...</td>\n",
       "      <td>10157901701015354_10157901714205354</td>\n",
       "      <td>95475020353_10157901701015354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>brietbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>10159620405955354_10159620498240354</td>\n",
       "      <td>Mike Daniels How so?  Do you have a 401k?  Hav...</td>\n",
       "      <td>10159620405955354_10159620415210354</td>\n",
       "      <td>95475020353_10159620405955354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>brietbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>10159656230075354_10159656251530354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10159656230075354_10159656232315354</td>\n",
       "      <td>95475020353_10159656230075354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>brietbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>10153245599621130_10153245817406130</td>\n",
       "      <td>Whenever I see a guy trolling I get the same u...</td>\n",
       "      <td>10153245599621130_10153245664966130</td>\n",
       "      <td>18468761129_10153245599621130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>huffpo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>10158434860435354_10158434922240354</td>\n",
       "      <td>Carlye Archibeque ACA is still around so who's...</td>\n",
       "      <td>10158434860435354_10158434867425354</td>\n",
       "      <td>95475020353_10158434860435354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>brietbart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           comment_id  \\\n",
       "0           0  10159788572690354_10159788622410354   \n",
       "1           1  10155327674521130_10155327912376130   \n",
       "2           2    1234985053182879_1235051949842856   \n",
       "3           3   10156819866680354_1696714377242759   \n",
       "4           4  10156242997995354_10156243051735354   \n",
       "5           5  10157901701015354_10157901768510354   \n",
       "6           6  10159620405955354_10159620498240354   \n",
       "7           7  10159656230075354_10159656251530354   \n",
       "8           8  10153245599621130_10153245817406130   \n",
       "9           9  10158434860435354_10158434922240354   \n",
       "\n",
       "                                             comment  \\\n",
       "0  You'll have to survive the mass hysteria and c...   \n",
       "1  Ummm...thanks. \"Not trying to be rude but\" is ...   \n",
       "2  Get rid of the cap all together. Include all w...   \n",
       "3   We will stay on the Trump train more than ever .   \n",
       "4  Becca Portera But....but....Obamacare took car...   \n",
       "5  David\"  Hell the Democrats control the Media n...   \n",
       "6  Mike Daniels How so?  Do you have a 401k?  Hav...   \n",
       "7                                                NaN   \n",
       "8  Whenever I see a guy trolling I get the same u...   \n",
       "9  Carlye Archibeque ACA is still around so who's...   \n",
       "\n",
       "                     parent_comment_id                 parent_post_id  \\\n",
       "0  10159788572690354_10159788608450354  95475020353_10159788572690354   \n",
       "1  10155327674521130_10155327709241130  18468761129_10155327674521130   \n",
       "2    1234985053182879_1235001863181198  18468761129_10153685924816130   \n",
       "3  10156819866680354_10156819873650354  95475020353_10156819866680354   \n",
       "4  10156242997995354_10156243010900354  95475020353_10156242997995354   \n",
       "5  10157901701015354_10157901714205354  95475020353_10157901701015354   \n",
       "6  10159620405955354_10159620415210354  95475020353_10159620405955354   \n",
       "7  10159656230075354_10159656232315354  95475020353_10159656230075354   \n",
       "8  10153245599621130_10153245664966130  18468761129_10153245599621130   \n",
       "9  10158434860435354_10158434867425354  95475020353_10158434860435354   \n",
       "\n",
       "   num_angrys  num_hahas  num_loves  num_sads  num_thankfuls  num_wows  \\\n",
       "0           0          0          0         0              0         0   \n",
       "1           0          0          1         0              0         0   \n",
       "2           0          0          0         0              0         0   \n",
       "3           0          0          0         0              0         0   \n",
       "4           0          0          0         0              0         0   \n",
       "5           0          0          0         0              0         0   \n",
       "6           0          0          0         0              0         0   \n",
       "7           0          0          1         0              0         0   \n",
       "8           0          0          0         0              0         0   \n",
       "9           0          0          0         0              0         0   \n",
       "\n",
       "   total_reaction    fb_page  \n",
       "0               8  brietbart  \n",
       "1              37     huffpo  \n",
       "2               9     huffpo  \n",
       "3               9  brietbart  \n",
       "4              23  brietbart  \n",
       "5              13  brietbart  \n",
       "6               9  brietbart  \n",
       "7              15  brietbart  \n",
       "8               8     huffpo  \n",
       "9              16  brietbart  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reader = pd.read_csv('comments_csv',iterator=True, chunksize=10,lineterminator='\\n' )\n",
    "reader.get_chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "\n",
    "#group should be 'hp' or 'bb'\n",
    "#rt should be 'lst' or 's'\n",
    "def comments_gen(group, num, rt):\n",
    "    hp_id = 18468761129 #fb group id for huffpo\n",
    "    bb_id = 95475020353 #fb group id for brietbart\n",
    "    \n",
    "    if group == 'hp':\n",
    "        group_id = hp_id\n",
    "        group_col = 'huffpo'\n",
    "    elif group =='bb':\n",
    "        group_id = bb_id\n",
    "        group_col = 'brietbart'\n",
    "    else:\n",
    "        print('invalid group')\n",
    "        return\n",
    "    \n",
    "    reader = pd.read_csv('comments_csv',iterator=True, chunksize=num,lineterminator='\\n' )\n",
    "    \n",
    "    for df_chunk in reader:\n",
    "        single_group = df_chunk[df_chunk.fb_page==group_col].dropna()\n",
    "        \n",
    "        if rt == 's':\n",
    "            yield single_group['comment']\n",
    "        if rt == 'lst':\n",
    "            yield single_group['comment'].tolist()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bb tokenization time: 231.6587655544281\n",
      "hp tokenization time: 220.4470658302307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:22: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasped time: 342.5961353778839\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "TOP_N = 50000\n",
    "bb_tok=Tokenizer(num_words=TOP_N, oov_token='<unk>' )\n",
    "\n",
    "bb_tok.fit_on_texts(comments_gen(group='bb',num=1000, rt='lst'))\n",
    "\n",
    "with open('bb-50k-tok.pickle', 'wb') as handle:\n",
    "    pickle.dump(bb_tok, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('bb tokenization time: {}'.format(time.time() - start))\n",
    "\n",
    "hp_start = time.time()\n",
    "hp_tok = Tokenizer(num_words=TOP_N, oov_token='<unk>')\n",
    "hp_tok.fit_on_texts(comments_gen(group='hp',num=1000,rt='lst'))\n",
    "\n",
    "with open('hp-50k-tok.pickle', 'wb') as handle:\n",
    "    pickle.dump(hp_tok, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('hp tokenization time: {}'.format(time.time() - hp_start ))\n",
    "\n",
    "\n",
    "def just_comments_to_file(group, num): #group should be 'bb' or 'hp'\n",
    "    for chunk in comments_gen(group, num, 's'):\n",
    "        chunk.to_csv(\"{}_all_comments.csv\".format(group), mode='a')\n",
    "\n",
    "        \n",
    "start = time.time()\n",
    "just_comments_to_file('hp',2000)\n",
    "just_comments_to_file('bb',2000)\n",
    "print('elasped time: {}'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasped time: 337.34581756591797\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def just_comments_to_file(group, num): #group should be 'bb' or 'hp'\n",
    "    for chunk in comments_gen(group, num, 's'):\n",
    "        chunk.to_csv(\"{}_all_comments.csv\".format(group), mode='a',header=['comment'])\n",
    "\n",
    "        \n",
    "start = time.time()\n",
    "just_comments_to_file('hp',2000)\n",
    "just_comments_to_file('bb',2000)\n",
    "print('elasped time: {}'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7881969\n",
      "7063461\n"
     ]
    }
   ],
   "source": [
    "all_bb = pd.read_csv('bb_all_comments.csv')\n",
    "all_hp = pd.read_csv('hp_all_comments.csv')\n",
    "print(len(all_bb))\n",
    "print(len(all_hp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', 'You'll have to survive the mass hysteria and chaos first. People are going to come for what you have.'], dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bb.head().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = pd.read_csv('comments_csv',iterator=True, chunksize=1000,lineterminator='\\n' )\n",
    "\n",
    "start = time.time()\n",
    "lst = [comment for comment in comment_itr(make_bb_comments()) ]\n",
    "end = time.time()\n",
    "\n",
    "print('elasped time to process {} samples: {}'.format(len(lst),end-start))\n",
    "\n",
    "with open('bb_train_datav0.json', 'w') as outfile:\n",
    "    json.dump(lst,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bb_train_datav0.json\") as f:\n",
    "    data=json.load(f)\n",
    "    \n",
    "less_20 = list(filter(lambda x: len(x) < 20, data))\n",
    "with open('bb_train<20.json','w') as out:\n",
    "    json.dump(less_20,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

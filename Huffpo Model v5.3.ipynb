{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.backend import clear_session\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clean_hp_comments.json') as json_file:  #first 1mill bb comments\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hp_tok = Tokenizer(oov_token='<unk>')\n",
    "hp_tok.fit_on_texts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hp_tok.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hp-v5-tok.pickle', 'wb') as handle:\n",
    "    pickle.dump(hp_tok, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data = data\n",
    "\n",
    "seqs = hp_tok.texts_to_sequences(train_data)\n",
    "less_8_seqs = list(filter(lambda x: len(x) < 8, seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399347"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(less_8_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Seq Len: 7\n"
     ]
    }
   ],
   "source": [
    "MAXLEN = 7\n",
    "VOCAB = int(len(hp_tok.word_index))\n",
    "SEED = 42\n",
    "\n",
    "sequences = pad_sequences(less_8_seqs, maxlen=MAXLEN, padding='pre')\n",
    "\n",
    "print('Max Seq Len: %d' % MAXLEN)\n",
    "\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.15, random_state=SEED)\n",
    "\n",
    "\n",
    "#y_cat = to_categorical(y, num_classes=vocab_sz) #1-hot encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to optimize this later, use np arrays instead of python lists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, seqs took 57s to go through 1 mill samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 6, 300)            3000600   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1000)              3204000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10002)             10012002  \n",
      "=================================================================\n",
      "Total params: 16,216,602\n",
      "Trainable params: 16,216,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#NN definition\n",
    "model = Sequential()\n",
    "model.add(Embedding(VOCAB, 300, input_length=MAXLEN-1))\n",
    "model.add(Bidirectional(LSTM(500),merge_mode='concat'))\n",
    "model.add(Dense(VOCAB, activation='softmax'))\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 336049 samples, validate on 3395 samples\n",
      "Epoch 1/200\n",
      "336049/336049 [==============================] - 732s 2ms/step - loss: 3.7805 - acc: 0.3515 - val_loss: 4.6789 - val_acc: 0.3146\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.31458, saving model to weights/huffpo-v5.3-R2/best-weights.hdf5\n",
      "Epoch 2/200\n",
      "336049/336049 [==============================] - 751s 2ms/step - loss: 3.2887 - acc: 0.3971 - val_loss: 4.8406 - val_acc: 0.3049\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.31458\n",
      "Epoch 3/200\n",
      " 16192/336049 [>.............................] - ETA: 12:56 - loss: 2.6286 - acc: 0.5012"
     ]
    }
   ],
   "source": [
    "\n",
    "model_json = model.to_json()\n",
    "\"\"\"\n",
    "with open(\"models/hp-model-v5.3.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\"\"\"\n",
    "fpath = \"weights/huffpo-v5.3-R2/best-weights.hdf5\" #off of training acc\n",
    "model.load_weights(\"weights/huffpo-v5.3/best-weights.hdf5\") #prev run's weights\n",
    "checkpoint = ModelCheckpoint(fpath, monitor='val_acc', verbose=2, save_best_only=True, mode='max')\n",
    "\n",
    "BS = 32\n",
    "tb = TensorBoard(log_dir=\"tensorboard-logs/{}\".format('huffpo-modelv5.3-bilstm(R2)'))\n",
    "callback_lst = [checkpoint, tb]\n",
    "#steps_per_epoch is num of batches that make up 1 epoch, defaults to size of train set\n",
    "model.fit(X_train,y_train,batch_size=BS, validation_split=.01, epochs=200, callbacks=callback_lst, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

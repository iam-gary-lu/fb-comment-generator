{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.backend import clear_session\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('bb_all_comments.csv')\n",
    "temp = temp.rename(index=str, columns={\"You'll have to survive the mass hysteria and chaos first. People are going to come for what you have.\": \"comment\"})\n",
    "temp = temp.iloc[:,1:2]\n",
    "temp.to_csv('bb_all_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = pd.read_csv('bb_all_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "bb_data = pd.read_csv('bb_all_comments.csv')\n",
    "bb_data.comment=bb_data.comment.astype(str)\n",
    "bb_data=bb_data['comment']\n",
    "\n",
    "\n",
    "bb_data_lst = bb_data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bb tokenization time: 11.483397483825684\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "bb_500k_tok = Tokenizer(num_words=50000,oov_token='<unk>')\n",
    "bb_500k_tok.fit_on_texts(bb_data_lst[:500000])\n",
    "with open('bb-500k-tok.pickle', 'wb') as handle:\n",
    "    pickle.dump(bb_500k_tok, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('bb tokenization time: {}'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bb-500k-tok.pickle', 'rb') as handle:\n",
    "    bb_tok = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144151"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bb_tok.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data = bb_data_lst[:2000000]\n",
    "\n",
    "seqs = bb_tok.texts_to_sequences(train_data)\n",
    "less_20_seqs = list(filter(lambda x: len(x) <20, seqs))[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Seq Len: 19\n"
     ]
    }
   ],
   "source": [
    "MAXLEN = 19\n",
    "VOCAB = int(len(bb_tok.word_index))\n",
    "SEED = 42\n",
    "\n",
    "sequences = pad_sequences(less_20_seqs, maxlen=MAXLEN, padding='pre')\n",
    "\n",
    "print('Max Seq Len: %d' % MAXLEN)\n",
    "\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.15, random_state=SEED)\n",
    "\n",
    "\n",
    "#y_cat = to_categorical(y, num_classes=vocab_sz) #1-hot encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to optimize this later, use np arrays instead of python lists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, seqs took 57s to go through 1 mill samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 18, 300)           43245300  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 500)               1602000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 144151)            72219651  \n",
      "=================================================================\n",
      "Total params: 117,066,951\n",
      "Trainable params: 117,066,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#NN definition\n",
    "model = Sequential()\n",
    "model.add(Embedding(VOCAB, 300, input_length=MAXLEN-1))\n",
    "model.add(LSTM(500))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(VOCAB, activation='softmax'))\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dl-one/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 845750 samples, validate on 4250 samples\n",
      "Epoch 1/200\n",
      "845750/845750 [==============================] - 999s 1ms/step - loss: 8.3093 - acc: 0.0625 - val_loss: 8.2482 - val_acc: 0.0661\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.06612, saving model to weights/bb-v4/best-weights.hdf5\n",
      "Epoch 2/200\n",
      "845750/845750 [==============================] - 998s 1ms/step - loss: 8.1928 - acc: 0.0627 - val_loss: 8.2200 - val_acc: 0.0661\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.06612\n",
      "Epoch 3/200\n",
      "845750/845750 [==============================] - 998s 1ms/step - loss: 8.1775 - acc: 0.0625 - val_loss: 8.1702 - val_acc: 0.0661\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.06612\n",
      "Epoch 4/200\n",
      "116500/845750 [===>..........................] - ETA: 14:21 - loss: 8.1851 - acc: 0.0628"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395500/845750 [=============>................] - ETA: 8:49 - loss: 8.1687 - acc: 0.0632"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609300/845750 [====================>.........] - ETA: 4:37 - loss: 8.1699 - acc: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845750/845750 [==============================] - 995s 1ms/step - loss: 8.1674 - acc: 0.0627 - val_loss: 8.1530 - val_acc: 0.0661\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.06612\n",
      "Epoch 8/200\n",
      " 19700/845750 [..............................] - ETA: 16:13 - loss: 8.2199 - acc: 0.0612"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845750/845750 [==============================] - 996s 1ms/step - loss: 8.1684 - acc: 0.0625 - val_loss: 8.1965 - val_acc: 0.0661\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.06612\n",
      "Epoch 9/200\n",
      "234400/845750 [=======>......................] - ETA: 11:58 - loss: 8.1573 - acc: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510700/845750 [=================>............] - ETA: 6:33 - loss: 8.1653 - acc: 0.0626"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748400/845750 [=========================>....] - ETA: 1:54 - loss: 8.1687 - acc: 0.0624"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845750/845750 [==============================] - 995s 1ms/step - loss: 8.1687 - acc: 0.0624 - val_loss: 8.1225 - val_acc: 0.0661\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.06612\n",
      "Epoch 13/200\n",
      " 81000/845750 [=>............................] - ETA: 14:58 - loss: 8.1610 - acc: 0.0642"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329700/845750 [==========>...................] - ETA: 10:06 - loss: 8.1648 - acc: 0.0616"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580300/845750 [===================>..........] - ETA: 5:11 - loss: 8.1637 - acc: 0.0623"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845750/845750 [==============================] - 994s 1ms/step - loss: 8.1677 - acc: 0.0624 - val_loss: 8.1970 - val_acc: 0.0661\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.06612\n",
      "Epoch 17/200\n",
      "845750/845750 [==============================] - 996s 1ms/step - loss: 8.1676 - acc: 0.0625 - val_loss: 8.1881 - val_acc: 0.0661\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.06612\n",
      "Epoch 18/200\n",
      "828200/845750 [============================>.] - ETA: 20s - loss: 8.1681 - acc: 0.0626"
     ]
    }
   ],
   "source": [
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"models/bb-model-v4.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "fpath = \"weights/bb-v4/best-weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(fpath, monitor='val_acc', verbose=2, save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "BS = 100\n",
    "tb = TensorBoard(log_dir=\"tensorboard-logs/{}\".format('bb-modelv4'))\n",
    "callback_lst = [checkpoint, tb]\n",
    "#steps_per_epoch is num of batches that make up 1 epoch, defaults to size of train set\n",
    "model.fit(X_train,y_train,batch_size=BS, validation_split=.005, epochs=200, callbacks=callback_lst, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
